# Copy this to .env and fill in values. Backend loads backend/.env
# SECURITY: Generate a strong secret key for production!
DJANGO_SECRET_KEY=django-insecure-CHANGE-THIS-IN-PRODUCTION-use-python-secrets-token-urlsafe-50
DEBUG=False

# MongoDB Atlas (REQUIRED) - Follow MONGODB_ATLAS_SETUP.md for setup instructions
# Replace with your actual Atlas connection string:
MONGO_URI=mongodb+srv://smartland_admin:YOUR_PASSWORD@cluster0.xxxxx.mongodb.net/land_management?retryWrites=true&w=majority
MONGO_DB=land_management

# Admin login credentials - CHANGE THESE IN PRODUCTION!
ADMIN_EMAIL=smartland0990@admin.login.com
ADMIN_PASSWORD=smartlandbyme@21

# Production only (optional):
# ALLOWED_HOSTS=your-backend.railway.app,api.yourdomain.com
# CORS_ORIGINS=https://your-app.vercel.app,https://yourdomain.com

# AI Insights — use one or more (first available wins: HF → Gemini → OpenAI → GPT4All)
# Hugging Face (Inference API / router): https://huggingface.co/settings/tokens
# Ensure the token has Inference API access; free tier has limited credits.
HF_TOKEN=
# Optional: model id (default tries Kimi-K2-Instruct-0905 then Kimi-K2-Instruct with provider fallbacks)
# HF_MODEL=moonshotai/Kimi-K2-Instruct-0905
# Google Gemini (free tier)
GEMINI_API_KEY=
# OpenAI (optional, paid)
OPENAI_API_KEY=
# OPENAI_MODEL=gpt-4o-mini

# Local GPT4All (no network). Download a model with the GPT4All desktop app or CLI,
# then point this to the full path to the .gguf file, e.g.:
# GPT4ALL_MODEL_PATH=C:\Models\gpt4all-falcon-q4_0.gguf
GPT4ALL_MODEL_PATH=
